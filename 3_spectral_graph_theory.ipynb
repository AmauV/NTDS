{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 3: spectral graph theory\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Michaël Defferrard](http://deff.ch), [EPFL LTS2](https://lts2.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 3\n",
    "* Students: Baptiste Hériard-Dubreuil, Jean-Baptiste Membrado, Guilhem Noiraud, Amaury Véron \n",
    "* Dataset: Flight routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this milestone is to get familiar with the graph Laplacian and its spectral decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `No module named 'sklearn'` error when running the below cell, install [scikit-learn](https://scikit-learn.org) with `conda install scikit-learn` (after activating the `ntds_2018` environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote your graph as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E}, A)$, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, $A \\in \\mathbb{R}^{N \\times N}$ is the (weighted) adjacency matrix, and $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Import the adjacency matrix $A$ that you constructed in the first milestone.\n",
    "(You're allowed to update it between milestones if you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency =  np.load(\"adjacency.npy\")\n",
    "n_nodes =  len(adjacency[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "From the (weighted) adjacency matrix $A$, compute both the combinatorial (also called unnormalized) and the normalized graph Laplacian matrices.\n",
    "\n",
    "Note: if your graph is weighted, use the weighted adjacency matrix. If not, use the binary adjacency matrix.\n",
    "\n",
    "For efficient storage and computation, store these sparse matrices in a [compressed sparse row (CSR) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_adjacency = sparse.csr_matrix(adjacency)\n",
    "\n",
    "laplacian_combinatorial =  sparse.csgraph.laplacian(sparse_adjacency)\n",
    "laplacian_normalized =  sparse.csgraph.laplacian(sparse_adjacency, normed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of them as the graph Laplacian $L$ for the rest of the milestone.\n",
    "We however encourage you to run the code with both to get a sense of the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian =  laplacian_combinatorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the eigendecomposition of the Laplacian $L = U \\Lambda U^\\top$, where the columns $u_k \\in \\mathbb{R}^N$ of $U = [u_1, \\dots, u_N] \\in \\mathbb{R}^{N \\times N}$ are the eigenvectors and the diagonal elements $\\lambda_k = \\Lambda_{kk}$ are the corresponding eigenvalues.\n",
    "\n",
    "Make sure that the eigenvalues are ordered, i.e., $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "computation =  scipy.linalg.eig(laplacian.toarray(), left = True)\n",
    "eigenvectors = computation[1]\n",
    "eigenvalues =  computation[0]\n",
    "\n",
    "#Sort to have ordered eigenvalues\n",
    "idx = eigenvalues.argsort()  \n",
    "eigenvalues = np.round_(np.real(eigenvalues[idx]), 13) #to avoid the zero approximations\n",
    "eigenvectors = np.real(eigenvectors[:,idx])\n",
    "\n",
    "#print(eigenvalues)\n",
    "\n",
    "assert eigenvectors.shape == (n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03909034, 0.05542375, 0.0600207 , 0.06635115, 0.06818503,\n",
       "       0.08202385, 0.08870359, 0.10449155, 0.10522678, 0.10791315])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your choice of eigensolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We cannot use the sparse.linalg eigenvector solver, as it only computes a part of eigenvalues and eigenvectors. Instead, we use the scipy.linalg solver that does the whole computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We can write $L = S S^\\top$. What is the matrix $S$? What does $S^\\top x$, with $x \\in \\mathbb{R}^N$, compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**S is the incidence matrix of size $N \\times M$.**\n",
    "\n",
    "**$S^T$ is a matrix with $M$ lines and $N$ columns : on each line $j$ corresponding to the edge $j$, all the coefficients are null, except for the column corresponding to the output node where the value is $+1$, and for the input node, where the value is $-1$. If we consider $x \\in \\mathbb{R}^N$, then $S^T x$ is the vector with each coefficient being $x[i] - x[k]$, with $i$ being the output node for edge $j$, and $k$ being the input node.**\n",
    "\n",
    "**If we see $x$ as a function from $V$ to $\\mathbb{R}^N$, then each component $j$ of $S^T x$ is the derivative of the function along edge $j$. Globally, $S^T x$ is thus the gradient of the function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show that $\\lambda_k = \\| S^\\top u_k \\|_2^2$, where $\\| \\cdot \\|_2^2$ denotes the squared Euclidean norm (a.k.a. squared $L^2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can express the squared Euclidian norm as follow :**\n",
    "\n",
    "**$\\| S^\\top u_k \\|_2^2 = (S^\\top u_k)^\\top S^\\top u_k = u_k^\\top S S^\\top u_k$**\n",
    "\n",
    "**And $S S^\\top = L$ so that : $\\| S^\\top u_k \\|_2^2 = u_k^\\top L u_k$**\n",
    "\n",
    "**As $u_k$ is an eigenvector, we have : $L u_k = \\lambda_k u_k$**\n",
    "\n",
    "**And finally, $\\| S^\\top u_k \\|_2^2 = \\lambda_k \\| u_k \\|_2^2 = \\lambda_k$**\n",
    "\n",
    "**As the $u_k$ eigenvectors are of norm 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the quantity $\\| S^\\top x \\|_2^2$ tell us about $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This squared norm is the squared norm of the gradient of $x$ if we consider $x$ as a function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the value of $u_0$, both for the combinatorial and normalized Laplacians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The sum of all the coefficients of a line or column is equal to zero by nature of the matrix construction. So $u_0$, composed of ones, is the trivial eigenvector of each Laplacian and its eigenvalue is zero.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verification : computation of the norm of A*1. If we get zero, it means that A*1=0.\n",
    "np.linalg.norm(np.dot(laplacian.toarray(),np.ones(3333).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Look at the spectrum of the Laplacian by plotting the eigenvalues.\n",
    "Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(eigenvalues)\n",
    "plt.title('Spectrum of the Laplacian')\n",
    "plt.xlabel('Sorted nodes')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have a lot of small eigenvalues, and only a few high ones. It seems to increase exponentially.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components are there in your graph? Answer using the eigenvalues only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 connected components.\n"
     ]
    }
   ],
   "source": [
    "#The number of connected components is equal to the multiplicity of the eigenvalue zero.\n",
    "connected_components=len(eigenvalues)-np.count_nonzero(eigenvalues)\n",
    "print('There are',connected_components,'connected components.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an upper bound on the eigenvalues, i.e., what is the largest possible eigenvalue? Answer for both the combinatorial and normalized Laplacians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of the eigenvalues and eigenvectors for the normalized Laplacian\n",
    "computation_norm =  scipy.linalg.eig(laplacian_normalized.toarray(), left = True)\n",
    "eigenvectors_norm = computation_norm[1]\n",
    "eigenvalues_norm =  computation_norm[0]\n",
    "\n",
    "#Sort to have ordered eigenvalues\n",
    "idx = eigenvalues_norm.argsort()  \n",
    "eigenvalues_norm = np.real(eigenvalues_norm[idx])\n",
    "eigenvectors_norm = np.real(eigenvectors_norm[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest possible eigenvalue for combinatorial Laplacian is equal to 249.217\n",
      "Largest possible eigenvalue for normalized Laplacian is equal to 2.000\n"
     ]
    }
   ],
   "source": [
    "#Largest eigenvalues\n",
    "print('Largest possible eigenvalue for combinatorial Laplacian is equal to %.3f'%eigenvalues[len(eigenvalues)-1])\n",
    "print('Largest possible eigenvalue for normalized Laplacian is equal to %.3f'%eigenvalues_norm[len(eigenvalues_norm)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the combinatorial Laplacian, there is no upper bound for the eigenvalues. In our case, the highest lambda is equal to 249.217.**\n",
    "\n",
    "**For the normalized Laplacian, eigenvalues are bounded by the upper bound 2, which is normal because we have a bipartite graph (departure nodes and arrival nodes).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Laplacian eigenmaps\n",
    "\n",
    "*Laplacian eigenmaps* is a method to embed a graph $\\mathcal{G}$ in a $d$-dimensional Euclidean space.\n",
    "That is, it associates a vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$.\n",
    "The graph $\\mathcal{G}$ is thus embedded as $Z \\in \\mathbb{R}^{N \\times d}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Biggest cluster, it is allowed to use networkx for this\n",
    "import networkx as nx\n",
    "\n",
    "connected = sorted(nx.connected_component_subgraphs(nx.from_numpy_matrix(adjacency)), key = len, reverse=True)\n",
    "biggest_cluster = connected[0]\n",
    "biggest_cluster_matrix = nx.to_numpy_matrix(biggest_cluster)\n",
    "sparse_cluster = sparse.csr_matrix(biggest_cluster_matrix)\n",
    "len(biggest_cluster_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What do we use Laplacian eigenmaps for? (Or more generally, graph embeddings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The main idea behind eigenmaps is to drastically reduce the number of dimensions we are working on with the original graph while losing the least information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Embed your graph in $d=2$ dimensions with Laplacian eigenmaps.\n",
    "Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "\n",
    "**Recompute** the eigenvectors you need with a partial eigendecomposition method for sparse matrices.\n",
    "When $k \\ll N$ eigenvectors are needed, partial eigendecompositions are much more efficient than complete eigendecompositions.\n",
    "A partial eigendecomposition scales as $\\Omega(k |\\mathcal{E}|$), while a complete eigendecomposition costs $\\mathcal{O}(N^3)$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a matrix of similarities \n",
    "# (ex: take the neighbours which distance d is smaller than epsilon, and put a weight of exp(-d^2/t), with t a parameter)\n",
    "\n",
    "def construct_similarities_by_neighbourhood(adjacency, eps, t):\n",
    "    n_nodes = adjacency.shape[0]\n",
    "    W = np.zeros((n_nodes, n_nodes))\n",
    "    distances = sparse.csgraph.shortest_path(adjacency, directed=False)\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_nodes):\n",
    "            if 0<distances[i,j] <= eps:\n",
    "                W[i,j] = np.exp(-distances[i,j]**2/t)\n",
    "                \n",
    "    return sparse.csr_matrix(W)\n",
    "\n",
    "\n",
    "W = construct_similarities_by_neighbourhood(sparse_cluster,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenmaps_from_similarities(W, d, renormed=False):\n",
    "\n",
    "    # Step 1: Compute the laplacian from the similarities as weight matrix\n",
    "    lap, degrees = sparse.csgraph.laplacian(W, normed=True, return_diag=True)\n",
    "\n",
    "    # Step 2: Compute the d eigenvectors associated to the d smallest eigenvalues (except for u0).\n",
    "    # For this, use a PARTIAL eigendecomposition\n",
    "    _, v = sparse.linalg.eigs(lap, k=d, which='SM')\n",
    "    \n",
    "    \n",
    "    # Step 4: Y is the concatenation of those eigenvectors multiplied by a parameter lambda so that Y'DY = eye.\n",
    "    # We have 1/lambda_i = u_i'(D)u_i, and each column of Y is u_i\n",
    "    # Then, the rows of Y are simply the coordonates for each node\n",
    "    factors = v.T.dot(np.diag(degrees).dot(v))\n",
    "    Y = np.real(v.dot(1/factors))\n",
    "\n",
    "    # optionnal : renorm the eigenvectors by the degrees\n",
    "    if renormed == True:\n",
    "        for i in range(d):\n",
    "            Y[:,i] = Y[:,i]/np.linalg.norm(Y[:,i])\n",
    "    \n",
    "    return Y, degrees\n",
    "\n",
    "Y, D = eigenmaps_from_similarities(W, 2, renormed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the nodes embedded in 2D. Comment on what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "plt.scatter(Y[:,0], Y[:,1], c=D, cmap=cm, vmin=min(D), vmax=max(D))\n",
    "cbar= plt.colorbar()\n",
    "cbar.set_label(\"degree (normalized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that we have a great proportion of airports that are situated on the left part and another part situated on the rightmost part. In the left vertical part, we can distinguish the points associated to degrees higher than 5 and the others. Also, we can define a group with the rightmost points. In the middle of those two groups, we see another possible cluster grouping the points in the elbow-shaped area.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the embedding $Z \\in \\mathbb{R}^{N \\times d}$ preserve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The $Z$ embedding preserves the similarity between nodes. This function from the space of the nodes to a $d$-dimension space will map similar points close to each other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Spectral clustering\n",
    "\n",
    "*Spectral clustering* is a method to partition a graph into distinct clusters.\n",
    "The method associates a feature vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$, then runs [$k$-means](https://en.wikipedia.org/wiki/K-means_clustering) in the embedding space $\\mathbb{R}^d$ to assign each node $v_i \\in \\mathcal{V}$ to a cluster $c_j \\in \\mathcal{C}$, where $k = |\\mathcal{C}|$ is the number of desired clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose $k$ and $d$. How did you get to those numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d=2 as we want to have a 2D plot. k is chosen from the Question 8 analysis : we believe we can separate our data into 3 groups, the great airports, the medium-sized airports, that form a great part of the data, and the smallest airports.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "1. Embed your graph in $\\mathbb{R}^d$ as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "   Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "1. If you want $k=2$ clusters, partition with the Fiedler vector. For $k > 2$ clusters, run $k$-means on $Z$. Don't implement $k$-means, use the `KMeans` class imported from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Use the computed cluster assignment to reorder the adjacency matrix $A$.\n",
    "What do you expect? What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_.tolist()\n",
    "\n",
    "idx2 = kmeans.labels_.argsort()  \n",
    "plt.spy(adjacency[idx2,:][:,idx2], markersize = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We expected a block diagonal matrix. We can see the three blocks but there are many points out of those blocks. It's probably because big airports are also connected with smaller ones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "If you have ground truth clusters for your dataset, compare the cluster assignment from spectral clustering to the ground truth.\n",
    "A simple quantitative measure is to compute the percentage of nodes that have been correctly categorized.\n",
    "If you don't have a ground truth, qualitatively assess the quality of the clustering.\n",
    "\n",
    "Ground truth clusters are the \"real clusters\".\n",
    "For example, the genre of musical tracks in FMA, the category of Wikipedia articles, the spammer status of individuals, etc.\n",
    "Look for the `labels` in the [dataset descriptions](https://github.com/mdeff/ntds_2018/tree/master/projects/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can identify three areas on our matrix. ~600 nodes are highly connected, with others from the same area and from different areas. They would correspond to major hubs. The biggest part (~2600 nodes) are medium-sized airports, mostly connected to the major hubs. The remaining ~50 airports are very low-connected nodes. It seems that we are close to the ground truth even if it is difficult to make an estimation because of the many points out of the diagonal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Plot the cluster assignment (one color per cluster) on the 2D embedding you computed above with Laplacian eigenmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:,0],Y[:,1], c=kmeans.labels_, cmap='rainbow')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Why did we use the eigenvectors of the graph Laplacian as features? Could we use other features for clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We used the eigenvectors of the graph laplacian as it is the optimal solution for minimizing the sum of the distances weighted by the similarities (given the orthonormality of the features). This allow us to make similar points be close.**\n",
    "\n",
    "**We could have used other features, if they generate a space where some information is not constant. The best features are the one with the higher variation of similarities. In our case, we could have used directly the degree to have a similar result. A more promising idea could be to use the distances in order to create clusters.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
